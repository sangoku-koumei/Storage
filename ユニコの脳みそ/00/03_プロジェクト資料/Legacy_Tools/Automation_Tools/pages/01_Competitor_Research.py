import streamlit as st
from duckduckgo_search import DDGS
import pandas as pd
from openai import OpenAI
import time
import requests
from bs4 import BeautifulSoup
import urllib.parse
import json
import os

# --- Bridge Helper ---
DATA_DIR = "c:\\Users\\user\\Desktop\\ä¿ç®¡åº«\\ãƒ¦ãƒ‹ã‚³ã®è„³ã¿ã\\Automation_Tools\\data"
os.makedirs(DATA_DIR, exist_ok=True)
STRATEGY_FILE = os.path.join(DATA_DIR, "latest_strategy.json")

# --- 3. Save Data Bridge (Updated for Multi-Account) ---
def save_strategy_data(strategy_text, keyword, project_name="default"):
    """
    Save the generated strategy to a JSON file for the 02 tool to pick up.
    Multi-Account: Saves as `strategy_{project_name}.json`
    """
    # Clean project name
    safe_name = "".join([c for c in project_name if c.isalnum() or c in ('-', '_')]).strip()
    if not safe_name: safe_name = "default"
    
    filename = f"strategy_{safe_name}.json"
    filepath = os.path.join(DATA_DIR, filename)

    data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "project_name": safe_name,
        "keyword": keyword,
        "strategy_content": strategy_text
    }
    
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        st.toast(f"âœ… Strategy Saved: {filename}", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"Failed to save strategy data: {e}")

# --- Main App ---
st.title("ğŸ•µï¸ Competitor Research (Naked Strategy)")

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ”‘ API Keys")
    openai_key = st.text_input("OpenAI API Key", type="password")
    
    st.divider()
    # Project Name Input in Sidebar for better layout
    project_name = st.text_input("Project / Brand Name", value="default", help="Used for file saving (Alphanumeric)")
    
    debug_mode = st.checkbox("ğŸ› Debug Mode", value=True)

if not openai_key:
    st.warning("ğŸ‘ˆ OpenAI API Key required")
    st.stop()

client = OpenAI(api_key=openai_key)

col1, col2 = st.columns([1, 2])
with col1:
    search_theme = st.text_input("èª¿æŸ»ãƒ†ãƒ¼ãƒ", "æººæ„›") # Default to simple keyword, logic adds context
with col2:
    target_url = st.text_input("ã‚ãªãŸã®URL (Gapåˆ†æç”¨)", placeholder="https://...")

# Search Assist Buttons
st.markdown("### ğŸ”— Search Assist (Manual Discovery)")
cols = st.columns(6)
for pf_name, config in PLATFORM_CONFIG.items():
    q = urllib.parse.quote(f"site:{config['domain']} {search_theme}")
    url = f"https://www.google.com/search?q={q}"
    cols[list(PLATFORM_CONFIG.keys()).index(pf_name)].link_button(f"ğŸ” {pf_name}", url)
st.divider()

if st.button("ğŸš€ Start Deep Individual Analysis"):
    st.info(f"Searching & Analyzing '{search_theme}' with Context Queries... (Deep Precision Mode)")
    
    full_report_data = ""
    
    # Progress Container
    prog_bar = st.progress(0)
    status_box = st.empty()
    
    platforms_list = list(PLATFORM_CONFIG.keys())
    
    for i, pf_name in enumerate(platforms_list):
        pf_config = PLATFORM_CONFIG[pf_name]
        status_box.markdown(f"**ğŸ•µï¸â€â™‚ï¸ Analyzing: {pf_name}**")
        
        # Debug Log Area
        log_area = None
        if debug_mode:
            with st.expander(f"ğŸ› Debug & Logs: {pf_name}", expanded=False):
                log_area = st.container()

        # 1. Smart Search (Context + Blacklist)
        results = smart_search(search_theme, pf_name, pf_config['domain'], log_area)
        
        if not results:
            if log_area: log_area.warning("No valid direct accounts found even with context queries.")
            full_report_data += f"\n### {pf_name}\n(æœ‰åŠ¹ãªç«¶åˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ)\n"
            continue
            
        if log_area: 
            log_area.success(f"Found {len(results)} valid targets. Starting Individual Analysis (gpt-4o-mini)...")

        # 2. Individual Analysis Loop
        platform_insights = f"### â–  {pf_name} Analysis\n"
        
        for idx, item in enumerate(results):
            # A. Direct Fetch (Good for Note/Tips)
            direct_body = fetch_content(item['href'])
            
            # B. Content Scout (For Wall Platforms or if Direct failed)
            # If direct body is short (<200 chars) or it's a Wall platform, use scout
            scouted_content = ""
            if not direct_body or len(direct_body) < 200 or pf_name in ["Instagram", "Twitter", "X", "YouTube"]:
                with st.spinner(f"ğŸ•µï¸Scouting posts for {item['title']}..."):
                     # Re-use headers from search
                    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36"}
                    scouted_content = scout_related_posts(headers, item['href'], item['title'], pf_config['domain'])
            
            # Combine content
            item['body'] = item.get('body', '') + "\n" + (direct_body if direct_body else "")
            item['extra_content'] = scouted_content
            
            # Analyze Individually
            analysis = analyze_single_item(client, item, pf_name)
            
            # Display Realtime
            with st.expander(f"ğŸ“ Deep Analysis: {item['title']}", expanded=True):
                st.markdown(f"**URL**: {item['href']}")
                st.markdown(analysis)
            
            # Append to log
            platform_insights += f"\n#### Target {idx+1}: {item['title']}\nURL: {item['href']}\n{analysis}\n"
            time.sleep(0.5)

        full_report_data += platform_insights
        prog_bar.progress((i+1)/len(platforms_list))

    status_box.success("All Platforms Analyzed. Generating Master Market Strategy Bible...")
    
    # Final Report (Synthesis using GPT-4o for quality)
    final_prompt = f"""
    ã‚ãªãŸã¯ã€Œä¼èª¬ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ»ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ã‚¹ãƒˆã€ã§ã™ã€‚
    ã“ã‚Œã¾ã§ã®è†¨å¤§ãªç«¶åˆèª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã®å¸‚å ´ã‚’å®Œå…¨ã«åˆ¶åœ§ã™ã‚‹ãŸã‚ã®**ã€Œç©¶æ¥µã®å¸‚å ´æ”»ç•¥ãƒã‚¤ãƒ–ãƒ«ï¼ˆWhitepaperï¼‰ã€**ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    ã€è¦ä»¶ã€‘
    1. **åˆ†é‡**: A4ç”¨ç´™5æšã€œ10æšç›¸å½“ï¼ˆ10,000æ–‡å­—ä»¥ä¸Šã‚’ç›®æŒ‡ã™ï¼‰ã€‚åœ§å€’çš„ãªæƒ…å ±å¯†åº¦ã«ã™ã‚‹ã“ã¨ã€‚
    2. **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: HTMLå½¢å¼ã€‚è¦‹å‡ºã—ã€ç®‡æ¡æ›¸ãã€å¤ªå­—ã€ãã—ã¦**ã€Œè¡¨ï¼ˆTableï¼‰ã€**ã‚’å¤šç”¨ã™ã‚‹ã“ã¨ã€‚
    3. **è¦–è¦šåŒ–**: ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€æˆ¦ç•¥ãƒãƒˆãƒªã‚¯ã‚¹ãªã©ã‚’è¡¨ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã€‚
    
    ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
    ãƒ†ãƒ¼ãƒ: {search_theme}
    ç«¶åˆåˆ†æãƒ­ã‚°: {full_report_data}
    
    ã€ç›®æ¬¡æ§‹æˆæ¡ˆã€‘
    
    # Chapter 1: Market Intelligence (å¸‚å ´æ§‹é€ ã®è§£æ˜)
    *   **Keyword Ecosystem**: ã“ã®å¸‚å ´ã§ã€ŒãŠé‡‘ã«ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã¨ã€Œé›†å®¢ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã®ãƒãƒƒãƒ—ã€‚
    *   **Competitor Landscape**: ç«¶åˆã®ãƒã‚¸ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒ—ï¼ˆè¡¨ã§è¡¨ç¾ï¼‰ã€‚
    
    # Chapter 2: The "Winner's Format" (å‹è€…ã®å‹)
    *   **Content Architecture**: ä¸Šä½å‹¢ãŒå…±é€šã—ã¦æ¡ç”¨ã—ã¦ã„ã‚‹ã€ŒæŠ•ç¨¿ã®é‰„æ¿æ§‹æˆã€ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŒ–ã—ã¦æç¤ºã€‚
    *   **Sensory Words List**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è„³é«„ã«éŸ¿ãã€Œã‚­ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã®ãƒªã‚¹ãƒˆï¼ˆè¡¨å½¢å¼ï¼‰ã€‚
    
    # Chapter 3: Strategy Matrix (æˆ¦ç•¥ãƒãƒˆãƒªã‚¯ã‚¹)
    *   å„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆInsta, Note, X, etc.ï¼‰ã”ã¨ã®å½¹å‰²ã¨é€£æºæˆ¦ç•¥ã€‚
    *   | Platform | Role | KPI | Content Type |
    *   |---|---|---|---|
    
    # Chapter 4: Action Roadmap (æ˜æ—¥ã‹ã‚‰ã®è¡Œå‹•è¨ˆç”»)
    *   **Day 1-7**: ç«‹ã¡ä¸Šã’æœŸã®å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã€‚
    *   **Day 8-30**: ãƒ•ã‚¡ãƒ³åŒ–ã®ãŸã‚ã®æŠ•ç¨¿ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ¡ˆã€‚
    
    # Chapter 5: Advanced Monetization (ãƒãƒã‚¿ã‚¤ã‚ºã®æ¥µæ„)
    *   ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¸ã®å°ç·šè¨­è¨ˆã€‚
    *   é«˜å˜ä¾¡å•†å“ã‚’å£²ã‚‹ãŸã‚ã®å¿ƒç†ãƒˆãƒªã‚¬ãƒ¼ã®å®Ÿè£…æ–¹æ³•ã€‚
    
    â€»ã“ã‚Œã¯ã€Œå˜ãªã‚‹è¦ç´„ã€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œæˆ¦ç•¥æŒ‡å°æ›¸ã€ã§ã™ã€‚
    èª­è€…ãŒãã®ã¾ã¾ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°è³‡æ–™ã¨ã—ã¦ä½¿ãˆã‚‹ãƒ¬ãƒ™ãƒ«ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    
    try:
        res = client.chat.completions.create(
            model="gpt-4o", # Synthesis needs intelligence
            messages=[{"role":"user", "content": final_prompt}],
            temperature=0.7
        )
        report_html = res.choices[0].message.content.replace("```html", "").replace("```", "")
        
        st.components.v1.html(report_html, height=1000, scrolling=True)
        st.download_button("ğŸ“¥ Download Strategy Bible", report_html, "Strategy_Bible.html")
        
        # Bridge to 02
        save_strategy_data(report_html, search_theme, project_name)
        
    except Exception as e:
        st.error(f"Report Generation Error: {e}")
