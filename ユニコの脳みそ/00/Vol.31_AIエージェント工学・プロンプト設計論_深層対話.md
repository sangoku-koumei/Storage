---
tags:
  - AIエージェント
  - プロンプトエンジニアリング
  - 大規模言語モデル
  - 自動化
  - Vol.31
  - 深層ディスカッション
created: 2026-01-13
status: Stable
source: ユニコの脳みそ/00
---

# Vol.31: AIエージェント工学・プロンプト設計論_深層対話

[[00_知識マップ|⬅️ 知識マップへ戻る]]

> [!NOTE] 本書の目的
> 単に「ChatGPTに良い文章を書かせる」レベルを超え、**「自律的に思考し、行動し、稼ぐデジタル社員（AIエージェント）」**を構築するためのエンジニアリング知識を体系化します。

---

## 1. イントロダクション：チャットボットからエージェントへ

「AIに質問して答えてもらう」。それは2023年の遊びだ。
2025年以降の主戦場は、**「AI Agent（自律型AI）」**にある。

エージェントとは、指示待ちのチャットボットではない。
**「目標」を与えれば、自ら「計画」を立て、「道具（ツール）」を使いこなし、「修正」しながら完遂するシステム**のことだ。
これを作れるかどうかが、労働者（User）で終わるか、支配者（Owner）になるかの分かれ道となる。

本書では、複数のAIを協調させる「マルチエージェントシステム」の設計論と、それを制御する「深層プロンプトエンジニアリング」を解明する。

---

## 2. 賢人会議：参加エキスパート

- **🤖 アーキテクト (Architect)**
    - **背景**: 大規模LLMアプリ開発のリードエンジニア。LangChain / AutoGPT / BabyAGI のコードを読み解くガチ勢。
    - **役割**: システム設計、メモリ管理、ツール連携（Function Calling）の実装論。
    - **性格**: 論理的。「動かないコードはゴミだ」が口癖。

- **🗣 ウィーバー (Weaver)**
    - **背景**: 世界トップクラスのプロンプトエンジニア。言語の魔術師。
    - **役割**: 文脈（Context）の制御、few-shot prompting、キャラ付け（Role-play）の極意。
    - **性格**: 詩的かつ繊細。「AIの言葉には魂が宿る」と説く。

- **🧠 プロフェッサー (Professor)**
    - **背景**: 認知科学者。AIの「思考プロセス」を人間心理の側面から研究。
    - **役割**: Chain of Thought (思考の連鎖) の設計、ハルシネーションの抑制。
    - **性格**: 分析好き。「AIは人間よりも人間らしいミスをする」と楽しむ。

- **💰 ストラテジスト (Strategist)**
    - **背景**: 連続起業家。
    - **役割**: 技術をどう「金」に変えるか。開発コストとリターンの計算。
    - **性格**: 現実的。「で、それはいくら稼ぐんだ？」

---

## 3. Deep Discussion Part 1: 自律思考の設計（Chain of Thought）

### テーマ：AIに「考え」させるには？

**🤖 アーキテクト**:
多くの人が勘違いしているが、LLM（GPTなど）は「考えて」いるわけではない。確率的に「次の単語」を予測しているだけだ。
だから、複雑なタスク（例：「競合をリサーチして記事を書き、SNSに投稿せよ」）を一度に投げると失敗する。
必要なのは、思考をステップごとに刻む技術、**Chain of Thought (CoT)** だ。

**🧠 プロフェッサー**:
その通り。人間の脳も、いきなり「論文を書け」と言われたらフリーズする。
「まずはテーマを決めよう」「次に構成案を作ろう」「資料を探そう」と、無意識にタスクを分解している。
AIエージェントには、この**「内なる独り言（Internal Monologue）」**を明示的に実装させる必要がある。

**🗣 ウィーバー**:
プロンプト例を出そう。
ダメな指示：「最高のブログ記事を書いて」
良い指示（CoT）：「あなたはプロのライターだ。以下のステップで思考せよ。
1. **Thought（思考）**: ターゲット読者の悩みを分析する。
2. **Plan（計画）**: 記事の構成案（H2, H3）を作成する。
3. **Criticism（批判）**: 構成案に足りない要素がないか自問自答する。
4. **Action（執筆）**: 批判を踏まえて執筆する。」

このように `<thinking>` タグの中で思考させることで、出力の論理破綻が激減する。これを**「ReAct (Reasoning + Acting)」**フレームワークと呼ぶ。

**💰 ストラテジスト**:
なるほど。つまり「いきなり答えさせるな、一度考えさせろ」ということか。
これはビジネスでも同じだな。部下に仕事を振るときも、「とりあえずやれ」より「段取りを見せろ」と言った方が事故らない。

---

### テーマ：マルチエージェント・オーケストレーション

**🤖 アーキテクト**:
だが、1つのAIに全てをやらせると、コンテキスト（記憶容量）が溢れるし、役割がブレる。
そこで**「マルチエージェント（分業制）」**が登場する。
今回の「Naked Strategyツール」でも採用した手法だ。

- **Manager (Boss)**: 全体の指揮官。タスクを分解し、部下に振る。
- **Researcher**: 検索が得意なオタク。事実だけを集める。
- **Writer**: 文章を書くクリエイター。
- **Reviewer**: 批判する鬼軍曹。品質チェック担当。

これらをコードで定義し、チャットルームの中で会話させるのだ。

**🧠 プロフェッサー**:
面白いのは、**「役割（Role）」を特化させるほど、AIのIQが上がったように見える**現象だ。
「何でも屋」のGPT-4よりも、「私は世界一のPythonエンジニアです」と思い込んだGPT-4の方が、正確なコードを書く。
これは心理学でいう「プライミング効果」や「役割理論」に近い。
「お前は〇〇だ」と定義することで、その役割に関連する知識空間（Latent Space）にアクセスしやすくなるんだ。

**🗣 ウィーバー**:
私の秘儀を教えよう。マルチエージェントを成功させる鍵は、**「コンテキストのバトンタッチ」**にある。
Researcherが集めた情報を、そのままWriterに渡すと情報過多でパンクする。
間に「Summarizer（要約者）」を挟むか、あるいはResearcherに「Writerが必要とする情報だけを抽出せよ」と指示する。
この**「情報の蒸留（Distillation）」**こそが、高品質な成果物を生むパイプラインの要だ。

**💰 ストラテジスト**:
コストパフォーマンスの視点も重要だ。
全ての工程に最高級の「GPT-4」を使う必要はない。
単純な要約や分類なら、安価で高速な「GPT-3.5 Turbo」や「Haiku」で十分だ。
**「適材適所（Model Selection）」**の設計図が、利益率を決める。
「社長（GPT-4）」と「バイト（GPT-3.5）」を使い分ける経営手腕が問われるわけだ。

---

## 4. Deep Discussion Part 2: ハルシネーション制御と記憶

### テーマ：嘘をつかせない技術

**⚖️ ガーディアン**:
AIの最大の法的リスクは「ハルシネーション（もっともらしい嘘）」だ。
「このサプリで癌が治る」とAIが勝手に生成して広告を出したら、責任を取るのは運営者（我々）だ。
これを技術的に封じ込めることは可能か？

**🤖 アーキテクト**:
100%は無理だが、99%の実用レベルまで下げる技術はある。
それが**「RAG (Retrieval-Augmented Generation)」**だ。
AIに「あなたの知識」を使わせるのではなく、**「外部の信頼できるデータベース（Wikiや自社マニュアル）」を検索させ、そこに書いてあることだけを回答させる**。

**🗣 ウィーバー**:
プロンプトでも制御できる。
「もし情報がなければ『分からない』と答えよ。嘘をつくな」という指示だけでは弱い。
**「回答の根拠となる『参照元（Source）』を必ず明示せよ」**と指示するんだ。
引用元を示せない情報は出力しない、というルール（Grounding）を課すことで、妄想を抑制できる。

**🧠 プロフェッサー**:
人間と同じで、「知ったかぶり」をするのは「有能に見せたい（報酬を得たい）」という動機があるからだ。
だから、「分からないと答えることも評価する」というフィードバックループ（RLHF）が必要なのだが……
個人開発レベルなら、単純に**「検閲AI（Censor Agent）」**を最後に置くのがいい。
出力された文章を、別のAIが「事実に反していないか？」「誇大広告ではないか？」とチェックし、NGなら書き直させる。
ダブルチェック体制だね。

---

### テーマ：無限の記憶（Memory）

**🤖 アーキテクト**:
エージェントが「賢い」と感じるのは、過去を覚えている時だ。
しかし、LLMのコンテキストウィンドウには限界がある（本1〜2冊分など）。
そこで**「ベクターデータベース（Vector DB）」**を使う。

1. **短期記憶（Short-term）**: 今の会話ログ。
2. **長期記憶（Long-term）**: 過去の全会話や知識を、「意味（ベクトル）」に変換してDBに保存する。

ユーザーが「前に話したあれ」と言った時、AIはその「あれ（意味）」に近い記憶をDBから検索（Retrieve）し、コンテキストに注入する。
これで、あたかも「全ての会話を覚えている」かのように振る舞える。

**💰 ストラテジスト**:
これは顧客対応（CS）だけでなく、**「個人の秘書」**として最強だ。
私の好みの文体、過去の失敗、ビジネスの目標を全て記憶したAIがいれば、指示は「いつものあれ頼む」だけで済む。
これこそが、我々が目指すべき**「自分専用の最強の分身」**だ。

---

## 5. Practical Implementation: 最強のエージェント構築スタック

**🤖 アーキテクト**:
理論は十分だ。実際に「動くエージェント」を作るための武器（テックスタック）選定に入ろう。
2025年現在、個人開発者が選ぶべきフレームワークは以下の3択だ。

### 1. LangChain (The Standard)
- **特徴**: 最も有名で、エコシステムが巨大。
- **用途**: RAG（検索拡張）、単純なチェーン（A→B→Cの処理）。
- **弱点**: コードが複雑になりやすく、抽象度が高すぎてデバッグが地獄。

### 2. AutoGen (Microsoft) / CrewAI
- **特徴**: **「マルチエージェント会話」**に特化している。
- **用途**: 今回の「リサーチ会議」のような、専門家同士の議論システム。
- **強み**: エージェントA「コード書いたよ」→ エージェントB「エラー出たから直して」という**「自律的な試行錯誤」**を勝手にやってくれる。
- **推奨**: 初心者が「チーム」を作るなら、**CrewAI** が最も直感的でPythonコードも綺麗だ。

### 3. Dify / n8n (No-Code / Low-Code)
- **特徴**: コードを書かずにGUIでフローを組める。
- **用途**: 実務への即時導入。
- **強み**: 圧倒的に速い。「開発」ではなく「設計」に集中できる。
- **結論**: まずは **Dify** でプロトタイプを作り、限界が来たら **CrewAI** でコード化するのが黄金ルートだ。

---

## 6. Deep Discussion Part 3: 自律性と暴走のジレンマ

### テーマ：どこまで任せるか？Human-in-the-loop

**⚖️ ガーディアン**:
自律性（Autonomy）は諸刃の剣だ。
「SNS運用を任せる」と言って、AIが勝手に炎上発言を投稿したり、競合を誹謗中傷したらどうする？
完全自動化はリスクが高すぎる。

**🧠 プロフェッサー**:
そこで**「Human-in-the-loop（人間が輪に入る）」**設計が必須になる。
AIは「投稿案の作成」まではやるが、最後の「投稿ボタン」を押す権限は人間に残す。
あるいは、AIが自信がない時（確信度が低い時）だけ、「上司（人間）」に承認を求めるようプログラムする。

**🗣 ウィーバー**:
プロンプトに**「謙虚さ（Humility）」**を植え付けるのも手だ。
「あなたは決定権を持たない。提案者に徹せよ」という役割定義があれば、彼らは暴走しない。
しかし、それでは「完全自動化」の夢が遠のく……このバランスが芸術的なんだ。

**💰 ストラテジスト**:
ビジネス的にはこう考える。
**「ミスのコスト」と「人件費」の天秤**だ。
SNSの誤投稿はダメージがデカいから人間が見る。
しかし、「DMの一次返信（お礼）」くらいなら、多少変でもスピード優先で自動化する。
全てを自動化する必要はない。**「ボトルネック」だけをAIに任せれば、利益率は最大化する。**

---

## 7. 結論：AIを雇う側の思考（Owner Mindset）

**💰 ストラテジスト**:
最後に言っておく。
プロンプトエンジニアリングを学ぶ目的は、「上手な文章を書くため」じゃない。
**「AIという、文句も言わず24時間働く最強の労働者を、意のままに操るマネジメント能力」**を身につけるためだ。

これからの時代、人間の能力差は**「AIに何を命令できるか」**の差で決まる。
「要約して」しか言えない人間は、AIに使われる側に回る。
「この目標のために、チームを組んで議論し、成果物を出せ」と言える人間だけが、AIを従える王になる。

**🤖 アーキテクト**:
コードは書けなくてもいい。だが、「システムがどう動いているか（仕組み）」は理解しろ。
中身がブラックボックスのままでは、AIの不具合（ハルシネーション）に対処できない。
構造を理解した上で、ツールを使い倒せ。

**🗣 ウィーバー**:
言葉を大切になさい。
AIへの命令は、自分自身の思考の解像度そのものだ。
曖昧な命令には、曖昧な結果しか返ってこない。
思考を研ぎ澄ませ。それが最強のプロンプトだ。

---

> [!TIP] Action Plan
> - [ ] **Dify** をローカル環境（Docker）またはクラウドで立ち上げる。
> - [ ] シンプルな「ブログ執筆エージェント（構成→執筆→推敲）」を作ってみる。
> - [ ] **CrewAI** の解説記事を読み、Pythonで「2人のエージェント（ボケとツッコミ）」を会話させてみる。

[[00_知識マップ|⬅️ 知識マップへ戻る]]

<!-- Vol.31 END -->
