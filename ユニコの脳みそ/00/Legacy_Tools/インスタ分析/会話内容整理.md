# Instagram競合・過去投稿調査分析ツール - 会話内容整理

Tags: #Instagram #Python #システム設計 #要件定義 #AIエージェント #Zettelkasten #開発プロセス
Links: [[USAGE]] [[ツール説明書]] [[技術資産__インスタ分析ツール]] [[2026-01-13_ツール開発・改善知見バイブル_深層対話]] [[2025-12-22-ニッチGPTs案]]

---

## 📋 プロジェクト概要

### 目的
Instagramの投稿を続けているが、伸びている投稿と伸びない投稿の違いが分析できていない問題を解決する。
- キャプションの違いなのか
- タグの違いなのか
- 投稿テーマの違いなのか

を明確にするツール。

### ターゲットユーザー
- Instagram運用初心者〜中級者
- 毎日投稿しているが伸び悩んでいる人
- 投稿構成の最適化がわからず手探りの人
- リサーチが苦手で、何の数字やどこが原因で伸びないのかわからない人

## 🎯 ツールの方向性

### 基本コンセプト
**「収集に特化し、分析はChatGPTなど外部AIに委ねる構成」**

- ツール自体はAI非搭載、またはOllamaなど無料のAIのみ
- 詳細な分析は出力結果をChatGPTなどAIに貼り付ければ良い形で出力
- データ収集と簡単な分析までをツールで行う

### なぜこの構成か
- 開発コストを抑えつつユーザー満足度が高い
- ユーザーの実際の悩みと一致（「何がバズるか分からない」→ 収集して見える化するだけで大きな価値）
- ChatGPTと併用しやすい（CSV＋プロンプトを貼るだけで詳細分析ができる）
- 段階的に機能追加しやすい（将来的に無料AI（Ollama）やLangchain連携でAI出力も可能）

## 🛠️ 機能要件

### 1. 自身の投稿分析・収集
**方法**: Instagram Graph API（公式API）
- 前提：Instagramビジネスアカウント ＋ Facebookアプリ連携が必要

**収集項目**:
- 投稿日時（時間帯分析用）
- キャプション全文（トーン・構成・絵文字使用率の分析）
- ハッシュタグ（タグの効果検証・頻度分析）
- いいね数・保存数・コメント数（エンゲージメント指標）
- メディアタイプ（写真/動画の傾向比較）
- 投稿時間帯（時間帯の効果検証用）
- 使用フィルター（可能なら）

### 2. 競合アカウントの投稿分析・収集
**方法**: Instaloader（非公式スクレイピング）
- アカウント指定 or 投稿URL指定で、その人の投稿を遡って分析
- ログインが必要（BANリスク対策として遅延を入れる）

**収集項目**:
- 投稿URL
- 投稿日・時刻
- キャプション全文
- ハッシュタグ
- いいね数（ログイン状態で取得可能）
- コメント数
- メディアタイプ（写真 or 動画識別）
- 再生数（動画の場合、後述の方法で取得）

**注意点**:
- 一度に大量取得するとBANリスクがあるため、1分1投稿などのディレイが必要
- 非公開アカウント以外は安定して取得可能

### 3. 再生数の取得
**方法**: Seleniumを使った自動スクリーンショット
- Instagramの投稿画面で再生数が表示されている部分を自動キャプチャ
- 画像OCRでCSV化も後から可能

**取得できる情報**:
- 投稿日時（画面に表示されている日付）
- キャプション、ハッシュタグ
- 再生数（リール or 動画）
- いいね数・コメント数

**注意点**:
- Instagramにログインした状態で使う必要がある
- Selenium操作中はIPブロックを防ぐために適切な遅延を入れるのが必須
- PCブラウザ上で動かす必要がある（スマホ画面は不可）

### 4. 簡易分析機能
- 平均いいね数、文字数、タグ数の相関をグラフで表示
- 自分 vs 競合で比較用グラフを作成
- PNG/CSV形式で出力

### 5. 出力形式
**CSV形式**:
- 自分と競合で別シートまたは別ファイルで出力
- 以下のカラム構成:
  - 投稿タイプ（自分/競合）
  - 投稿日時
  - いいね数
  - 保存数
  - コメント数
  - 再生数（動画の場合）
  - キャプション
  - ハッシュタグ
  - 投稿時間帯
  - メディアタイプ
  - 投稿URL

**ChatGPT用プロンプトテンプレート**:
- 「このCSVをChatGPTに貼れば分析できる」テンプレートを自動生成
- TXT形式で出力

## 📊 想定CSVフォーマット

```
投稿タイプ,投稿日時,いいね数,保存数,コメント数,再生数,キャプション,ハッシュタグ,投稿時間帯,メディアタイプ,投稿URL
自分,2024-12-01 19:00,123,45,10,,〇〇な毎日…,"#副業 #集客",19:00,写真,https://...
競合A,2024-11-30 21:00,340,112,25,5000,～,"#集客術",21:00,動画,https://...
```

## 🧠 ChatGPT分析テンプレート例

```
以下は私と競合のInstagram投稿データです。
キャプション、タグ、投稿時間、反応（いいね・保存）などをもとに、
私の投稿の伸び悩みの原因を分析してください。

---ここにCSV貼り付け---
```

## ⚠️ 開発時の注意点

### 法的・倫理的リスク（非公式スクレイピング）
- 利用規約違反になる可能性あり
- 商用販売する場合、スクレイピングベースは避ける or 非公開で使うべき
- **改善案**: 「自分の投稿だけ」ならAPI連携を推奨。競合データは、ユーザーにURL貼ってもらい、その投稿1件だけ収集するようにする（セーフゾーン）

### API利用のハードル
- Meta開発者登録が面倒
- トークン管理やリフレッシュの仕組みが必要
- **改善案**: ツール内で「Meta API連携セットアップガイド」を付属。ノーコード化（Streamlit＋設定ファイル）すれば、エンジニアでなくても扱いやすくなる

### 自動分析の難易度
- 感情分析や構成の分類などは、簡易的な集計だけでは限界がある
- **改善案**: 「ChatGPTにCSVを貼れば分析してくれるプロンプト」をツール内に用意（人間の知能で補う）。将来的にOllama（ローカルLLM）連携で無料AI対応も検討

## 🔮 今後のアップグレード候補（Ver.2以降）

- Ollama等のローカルAI対応（オフラインでも分析できる無料AI連携）
- データから「次にバズる投稿案」自動提案（AIによるネクスト戦略提案：構成・タグ）
- 投稿ジャンル分類（AIで「howto系・共感系・体験談系」など分類可視化）

## 💡 利用シナリオ

1. ツールで「自分と競合の投稿データを収集」
2. 自動で「キャプション傾向・タグ・時間帯・構成の違い」をグラフに出力
3. ChatGPTにCSVとテンプレを貼って、「伸びる投稿を真似するヒント」を得る
4. 次の投稿で改善を試す

## 🎯 技術スタック

- **言語**: Python
- **API連携**: Instagram Graph API（自分の投稿）
- **スクレイピング**: Instaloader（競合投稿）
- **自動化**: Selenium（再生数取得）
- **データ処理**: pandas
- **可視化**: matplotlib
- **UI**: Streamlit（推奨）

- **UI**: Streamlit（推奨）

---

## 🏗️ 深層対話：バズを「設計」するアーキテクチャの真髄

**テーマ**: ツールを「命令」から「対話」へ、そして「自律（Autonomous）」へ

**参加者**:
*   **Architect**: システムの根幹を設計する構造思想家。美しく堅牢な設計を志向。
*   **UX Designer**: ユーザーの「感情」と「操作感」を設計する体験の魔術師。
*   **AI Specialist**: LLMの出力品質と「知能」の統合を担当する技術者。
*   **PM (Product Manager)**: 「今、何を作るべきか」を決定し、市場価値を担保する。

---

### 第1章：なぜ「収集」と「分析」を分離したのか

**Architect**: 
このツールの設計思想において最も議論を呼んだのが、`基本コンセプト` にある「収集に特化し、分析は外部に委ねる」という点でしたね。

**UX Designer**: 
最初は「AIに全自動でアドバイスまでさせてほしい」という意見もありました。でも、あえてそれを切り離した。

**PM**: 
理由は明確です。当時のAI開発速度は凄まじく、ツールの中に固いロジックを組み込むと、すぐに陳腐化するからです。ChatGPT側（GPT-4oなど）の進化を最大限に活かすには、**「最高品質のデータを、最高に貼り付けやすい形式（CSV）で渡す」**ことこそが最大のユーザー体験（UX）だと判断しました。

**Architect**: 
**【設計原則1】 変動の激しい「知能（AI）」と、普遍的な「事実（データ）」を疎結合にせよ。**
これにより、ユーザーは自分のお気に入りのAI（Claude, Gemini, ChatGPT等）を自由に選んで分析できるようになりました。

### 第2章：スクレイピングという「刃（やいば）」の扱い方

**AI Specialist**: 
`競合アカウントの収集` で Instaloader を採用した点は、BANリスクとの戦いでもありましたね。

**UX Designer**: 
ユーザーに「ログインが必要ですよ」「1分1投稿のディレイが入りますよ」と正直に伝える。この `注意点` の明記は、一見不便に見えますが、実は「プロの道具」としての信頼感に繋がっています。

**Architect**: 
技術的な妥協ではありません。Instagramという巨大なエコシステムの中で生き残るための「生存戦略」です。

**PM**: 
**【設計原則2】 速度よりも「生存」を優先せよ。**
一気に1000件収集してアカウントが飛ぶより、10件を確実に、毎日記録し続けること。それが `2025-12-15-ツール作成アイデア` で語られた「継続的な収益化」の基盤です。

### 第3章：「再生数」というブラックボックスへの挑戦

**Architect**: 
`再生数の取得` で Selenium を使った自動キャプチャと OCR を提案したのは、APIでは取得できない「生の市場反応」を掴むためでした。

**AI Specialist**: 
画像OCRはまだ発展途上ですが、将来的には `Ver.2以降` の「ジャンル分類」と組み合わせることで、「このサムネイルのデザインなら、再生数が伸びやすい」という視覚的トレンドの数値化が可能になります。

**PM**: 
これが `2025-12-22-インスタ動画解析結果` で発見された「視覚的フック」の正体を暴くための武器になります。

### 第4章：エピローグ：ツールは「脳」の鏡である

**Architect**: 
結局、この `会話内容整理` を通じて我々が作り上げたのは、単なるPythonスクリプトではありません。

**AI Specialist**: 
使い手の「問い（問いの解像度）」を映し出す、鏡のようなインターフェースですね。

**PM**: 
このツールを使い込み、CSVデータを毎日眺めているユーザーは、やがてツールを使わなくても「バズの法則」を脳内でシミュレートできるようになります。ツールはその修行をサポートするための**「補助脳」**なんです。

**UX Designer**: 
その時、この `会話内容整理` の冒頭に書かれた「目的」は、単なる問題解決を超えて、「ビジネスプロデューサーの育成」へと昇華されているでしょう。

---

## 関連リンク
- [[USAGE]]
- [[ツール説明書]]
- [[技術資産__インスタ分析ツール]]
- [[2026-01-13_ツール開発・改善知見バイブル_深層対話]]
- [[2025-12-22-ニッチGPTs案]]
- [[2025-12-15-ツール作成アイデア]]
- [[SNS運用代行・知識統合バイブル【深層対話録】]]
- [[在宅ワーク考察]]
- [[00 Rules]]





